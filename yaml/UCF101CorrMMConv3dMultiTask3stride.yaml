!obj:pylearn2.train.Train {
    dataset: &train !obj:HumanActivityRecognition.dataset.UCF101Dataset_h5_MultiTask3.UCF101Dataset {
        data_path: '/Tmp/torabi/UCF101/t2LongVid240',
        data_path2: '/Tmp/torabi/HMDB51/t2LongVid240',
        split: 1,
        dataSize : 19074,
        dataSize2 : 3584,
        mutlipeAugment: 1,
        num_split: 1,
        nb_x: 20,
        nb_y: 20,
        nb_t : 119,
        which_set: 'train',
    },
    #model: !obj:pylearn2.monitor.push_monitor {
    #    model: !pkl: "/data/lisatmp3/torabi/UCF101/conv3Dresults/3layer_latest_t2Long240_model_MT21.pkl",
    #    name: "monitor_validation"
    #},
    model: !obj:pylearn2.models.mlp.MLP {
        batch_size: 48,
         layers: [
                 !obj:HumanActivityRecognition.model.GPUCorrMM3dConvReLU1.fft3dConvReLUPool {
                     layer_name: 'h0',
                     tied_b: 0,
                     W_lr_scale: .05,
                     b_lr_scale: .05,
                     num_channels: 64,
                     # MUST BE ONE, not supported in the current code
                     num_pieces: 1,
                     kernel_shape: [2, 2, 3],
                     kernel_stride: [2, 2, 1],
                     pool_shape: [2, 2],
                     pool_stride: [1, 1],
                     pool_temporal_shape: [1, 3],
                     pool_temporal_stride: [1, 2],
                     irange: .005,
                     max_kernel_norm: .9,
                 },
                 !obj:HumanActivityRecognition.model.GPUCorrMM3dConvReLU1.fft3dConvReLUPool {
                     layer_name: 'h1',
                     tied_b: 0,
                     W_lr_scale: .05,
                     b_lr_scale: .05,
                     num_channels: 128,
                     # MUST BE ONE, not supported in the current code
                     num_pieces: 1,
                     kernel_shape: [3, 3, 3],
                     kernel_stride: [1, 1, 1],
                     pool_shape: [2, 2],
                     pool_stride: [1, 1],
                     pool_temporal_shape: [1, 5],
                     pool_temporal_stride: [1, 2],
                     irange: .005,
                     max_kernel_norm: .9,
                 },
                 !obj:HumanActivityRecognition.model.GPUCorrMM3dConvReLU1.fft3dConvReLUPool {
                     layer_name: 'h2',
                     tied_b: 0,
                     W_lr_scale: .05,
                     b_lr_scale: .05,
                    num_channels: 320,
                     # MUST BE ONE, not supported in the current code
                     num_pieces: 1,
                     kernel_shape: [3, 3, 2],
                     kernel_stride: [1, 1, 1],
                     pool_shape: [2, 2],
                     pool_stride: [2, 2],
                     pool_temporal_shape: [1,26],
                     pool_temporal_stride: [1, 1],
                     irange: .005,
                     max_kernel_norm: .9,
                 },
                 !obj:pylearn2.models.mlp.RectifiedLinear {
                      layer_name: 'h3',
                      dim: 2000,
                      irange: .05,
                      #max_col_norm: 2.
                 },
                 !obj:HumanActivityRecognition.model.mlp.Softmax {
                      #max_col_norm: 1.9365,
                      layer_name: 'y',
                      n_classes: 152,
                      irange: .005,
                      pivot: 101,
                      costweight: 1,
                 },
    #             !obj:HumanActivityRecognition.model.mlp_with_source.CompositeLayerWithSource {
    #                  layer_name: 'y',
    #                  layers: [
    #                      !obj:pylearn2.models.mlp.Softmax {
    #                           #max_col_norm: 1.9365,
    #                           layer_name: 'y1',
    #                           n_classes: 101,
    #                           irange: .005,
    #                        },
    #                       !obj:pylearn2.models.mlp.Softmax {
    #                           #max_col_norm: 1.9365,
    #                           layer_name: 'y2',
    #                           n_classes: 51,
    #                           irange: .005,
    #                        },
    #                  ],
    #               },
           ],
           input_space: !obj:HumanActivityRecognition.space.Conv3DSpace {
                         shape: [20, 20, 119],
                         num_channels: 33,
                         axes: ['b', 0, 1, 't', 'c'],
          }, 
         
          #input_source : ['features'],
          #target_source: ['targets' , 'second_targets'],
    },
    algorithm: !obj:pylearn2.training_algorithms.sgd.SGD {
        learning_rate: .1,
        train_iteration_mode: 'even_sequential',
        init_momentum: .8,
        monitoring_dataset:
            {
                 #'train' : *train,
                 #'valid' : !obj:HumanActivityRecognition.dataset.UCF101Dataset_fft3.UCF101Dataset {
                 #   data_path: '/data/lisatmp3/torabi/UCF101/t5',
                 #   split: 1,
                 #   which_set: 'valid',
                 #},
                 'test' : !obj:HumanActivityRecognition.dataset.UCF101Dataset_h5_MultiTask3.UCF101Dataset {
                    data_path: '/Tmp/torabi/UCF101/t2LongVid240',
                    data_path2: '/Tmp/torabi/HMDB51/t2LongVid240',
                    split: 1,
                    dataSize : 3783,
                    dataSize2 : 1536,
                    mutlipeAugment: 1,
                    num_split: 1,
                    nb_x: 20,
                    nb_y: 20,
                    nb_t : 119,
                    which_set: 'test',
                 },
            },
        cost: !obj:pylearn2.costs.mlp.dropout.Dropout {
            input_include_probs: { 'h0' : 1., 'h1': 1.,'h2': 1.,'h3': .5, 'y': .5},
            input_scales: { 'h0': 1., 'h1': 1., 'h2': 1.,'h3': 2.,'y': 2.}
        },
        termination_criterion: !obj:pylearn2.termination_criteria.MonitorBased {
            channel_name: "test_y_misclass1",
            prop_decrease: 0.,
            N: 1000
        },
        #termination_criterion: !obj:pylearn2.termination_criteria.EpochCounter {max_epochs: 1}
    },
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'test_y_misclass1',
             save_path: "/data/lisatmp3/torabi/UCF101/conv3Dresults/3layer_best_t2Long240_model_MT2Stride.pkl"
        },
#       !obj:pylearn2.training_algorithms.sgd.MomentumAdjustor {
#            start: 1,
#            saturate: 250,
#            final_momentum: .6
#        },
#        !obj:pylearn2.training_algorithms.sgd.LinearDecayOverEpoch {
#            start: 1,
#            saturate: 250,
#            decay_factor: .01
#        }
    ],
    save_path: "/data/lisatmp3/torabi/UCF101/conv3Dresults/3layer_latest_t2Long240_model_MT2Stride.pkl",
    save_freq: 1
}
